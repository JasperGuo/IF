{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8945d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaqiguo/miniconda3/envs/deepfloyd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-03 08:44:43,655] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "FORCE_MEM_EFFICIENT_ATTN= 0 @UNET:QKVATTENTION\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jiaqiguo/miniconda3/envs/deepfloyd/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/v-xinyuzhu/local/bin/cuda111/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 111\n",
      "CUDA SETUP: Loading binary /home/jiaqiguo/miniconda3/envs/deepfloyd/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaqiguo/miniconda3/envs/deepfloyd/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/jiaqiguo/miniconda3/envs/deepfloyd did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from deepfloyd_if.pipelines import dream\n",
    "from deepfloyd_if.modules import T5Embedder, IFStageI\n",
    "from deepfloyd_if.finetune.adapter import inject_adapter\n",
    "from deepfloyd_if.finetune.adapter_diffusion import add_vtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a44f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "NUM_VTOKENS = 1\n",
    "\n",
    "BOTTLENECK_R = 2\n",
    "ADAPTER_SCALE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904b7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaqiguo/miniconda3/envs/deepfloyd/lib/python3.8/site-packages/huggingface_hub/file_download.py:1104: FutureWarning: The `force_filename` parameter is deprecated as a new caching system, which keeps the filenames as they are on the Hub, is now in place.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VToken ids: [32100]\n"
     ]
    }
   ],
   "source": [
    "t5 = T5Embedder(device=\"cpu\", torch_dtype=torch.float32, use_offload_folder=None)\n",
    "vtoken_seq, vtoken_ids = add_vtokens(t5, num_tokens=NUM_VTOKENS, init_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1855808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=704, out_features=2816, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(704, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (12): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (13): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (14): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (15): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "      (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "      (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "      (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4928, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4928, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4928, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4928, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(3520, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(3520, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(3520, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(3520, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (12): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (13): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (14): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (15): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Conv2d(704, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (activation_layer): Identity()\n",
       "  (encoder_pooling): Sequential(\n",
       "    (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): AttentionPooling(\n",
       "      (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    )\n",
       "    (2): Linear(in_features=4096, out_features=2816, bias=True)\n",
       "    (3): LayerNorm((2816,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (encoder_proj): Linear(in_features=4096, out_features=2816, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_I = IFStageI('IF-I-XL-v1.0', device=DEVICE, model_kwargs={\"precision\": 32})\n",
    "if_I.model.to(dtype=if_I.model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e43fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_test(t5, if_I, if_II, prompt: str, seed: int = 42) -> None:\n",
    "    init_result = dream(\n",
    "        t5=t5, if_I=if_I, if_II=if_II,\n",
    "        prompt=[prompt],\n",
    "        seed=seed,\n",
    "        if_I_kwargs={\n",
    "            \"guidance_scale\": 7.0,\n",
    "            \"sample_timestep_respacing\": \"smart100\",\n",
    "        },\n",
    "    )\n",
    "    if_I.show(init_result['I'], size=16)\n",
    "    if if_II is not None:\n",
    "        if_II.show(init_result['II'] , size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd4e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:27<00:00,  3.70it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_test(t5, if_I, None, \"a photo of a  doll, white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef77de3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(704, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(704, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(1408, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(1408, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2112, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2112, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (2): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(4928, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(4928, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (2): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Upsample()\n",
      "    (x_upd): Upsample()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(4928, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(4928, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(3520, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(3520, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (2): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Upsample()\n",
      "    (x_upd): Upsample()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(3520, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(3520, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n",
      "TimestepEmbedSequential(\n",
      "  (0): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(2112, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Identity()\n",
      "    (x_upd): Identity()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Conv2d(2112, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (1): AttentionBlock(\n",
      "    (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "    (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
      "    (attention): QKVAttention()\n",
      "    (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
      "    (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
      "    (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (2): ResBlock(\n",
      "    (in_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (h_upd): Upsample()\n",
      "    (x_upd): Upsample()\n",
      "    (emb_layers): Sequential(\n",
      "      (0): GELU(approximate='none')\n",
      "      (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
      "    )\n",
      "    (out_layers): Sequential(\n",
      "      (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.0, inplace=False)\n",
      "      (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (skip_connection): Identity()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<generator object Module.parameters at 0x7f11c6842740>,\n",
       " <generator object Module.parameters at 0x7f11c6842d60>,\n",
       " <generator object Module.parameters at 0x7f11c6842580>,\n",
       " <generator object Module.parameters at 0x7f11c6842eb0>,\n",
       " <generator object Module.parameters at 0x7f11c6842dd0>,\n",
       " <generator object Module.parameters at 0x7f11c6842cf0>,\n",
       " <generator object Module.parameters at 0x7f11c6842c80>,\n",
       " <generator object Module.parameters at 0x7f11c6842e40>,\n",
       " <generator object Module.parameters at 0x7f11c6842ac0>,\n",
       " <generator object Module.parameters at 0x7f11c6842c10>,\n",
       " <generator object Module.parameters at 0x7f11c403a0b0>,\n",
       " <generator object Module.parameters at 0x7f11c403a120>,\n",
       " <generator object Module.parameters at 0x7f11c403a190>,\n",
       " <generator object Module.parameters at 0x7f11c403a200>,\n",
       " <generator object Module.parameters at 0x7f11c403a270>,\n",
       " <generator object Module.parameters at 0x7f11c403a2e0>,\n",
       " <generator object Module.parameters at 0x7f11c403a350>,\n",
       " <generator object Module.parameters at 0x7f11c403a3c0>,\n",
       " <generator object Module.parameters at 0x7f11c403a430>,\n",
       " <generator object Module.parameters at 0x7f11c403a4a0>,\n",
       " <generator object Module.parameters at 0x7f11c403a510>,\n",
       " <generator object Module.parameters at 0x7f11c403a580>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inject_adapter(if_I.model, BOTTLENECK_R, ADAPTER_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f84a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=704, out_features=2816, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(704, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(704, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (13): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AdapterAttentionBlock(\n",
       "      (attn_block): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttention()\n",
       "        (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "        (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (adapter_block): BottleneckAdapter(\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 5632, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(5632, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(5632, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4928, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4928, 2816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2816, 8448, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 5632, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=5632, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2816, 2816, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4928, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4928, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4928, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 4224, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(4224, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(4224, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(3520, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(3520, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(2112, 6336, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(2112, 2112, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=4224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 3520, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(3520, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(3520, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2816, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2816, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 1408, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AdapterAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1408, 4224, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (encoder_kv): Conv1d(2816, 2816, kernel_size=(1,), stride=(1,))\n",
       "          (norm_encoder): GroupNorm32(32, 2816, eps=1e-05, affine=True)\n",
       "          (proj_out): Conv1d(1408, 1408, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (adapter_block): BottleneckAdapter(\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Upsample()\n",
       "        (x_upd): Upsample()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=2816, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (12): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2112, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(2112, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2112, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (13): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (14): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (15): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1408, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1408, 704, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 704, eps=1e-05, affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Conv2d(704, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (activation_layer): Identity()\n",
       "  (encoder_pooling): Sequential(\n",
       "    (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): AttentionPooling(\n",
       "      (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (q_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (v_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    )\n",
       "    (2): Linear(in_features=4096, out_features=2816, bias=True)\n",
       "    (3): LayerNorm((2816,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (encoder_proj): Linear(in_features=4096, out_features=2816, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_I.model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc99d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:24<00:00,  4.04it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_test(t5, if_I, None, \"a photo of a  doll, white background\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3082b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vtoken_embeds(t5: T5Embedder, ckpt: Union[Dict, str]) -> None:\n",
    "    if isinstance(ckpt, str):\n",
    "        _ckpt = torch.load(ckpt)\n",
    "    else:\n",
    "        _ckpt = ckpt\n",
    "    token_embeds = t5.model.get_input_embeddings().weight.data\n",
    "    for vid, vembed in _ckpt.items():\n",
    "        token_embeds[vid] = vembed.to(t5.model.device)\n",
    "\n",
    "        \n",
    "def load_unet_ckpt(if_I: IFStageI, ckpt_path: str) -> None:\n",
    "    state = torch.load(ckpt_path)\n",
    "    if_I.model = state\n",
    "    \n",
    "\n",
    "def set_adapter_scale(if_I: IFStageI, scale: float) -> None:\n",
    "    for fullname, module in if_I.model.named_modules():\n",
    "        if module.__class__.__name__ == \"AdapterAttentionBlock\":\n",
    "            module.adapter_scale = scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1bcba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"/data/jiaqi/if_ckpts/adapter_diffusion/unet-step-2000.bin\"\n",
    "load_unet_ckpt(if_I, CKPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26923a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vtoken_embeds(t5, CKPT_PATH.replace(\".bin\", \"-embeds.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e461bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.25it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_test(t5, if_I, None, \"a photo of a doll, white background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e86182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_test(t5, if_I, None, \"a photo of a doll in New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86947bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_adapter_scale(if_I, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cb25976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.24it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOQAAATkCAYAAADMwd8cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKB0lEQVR4nO3dW68k2Xkm5i8yMnOf6thNNsnmSdbMaGBJg/HAhu2587V/tAFf2IBt2IJmII5szUgUm2w22afqOuxjZoQvqpviGGazdtfb346qfB6hAF3sfnOtFSsO+WZAGuZ5ngsAAAAAaLG66wEAAAAAwCFRyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAo/Wr/NE0TfXhhx/W/fv3axiGb3tMAAAAAPBGmee5nj17Vu+//36tVl//DtwrFXIffvhh/fjHP44MDgAAAADeVh988EH96Ec/+tq/eaVC7v79+1VV9X/91V/97n9/HdF37MJv7C11bEt+L9Fbk2+RA9mzyxVetWCc4/lNLHTVFjqstAOZJnyNQ7gJzHc9gB5LnmZyb8zRsGBW2FLPpwUvGbxJnj17Vn/xF3/xSt3ZKxVyXxUu9+/fV8jdKuwwyo3lFnLLfRBd6oodyp5druVuNMfzm1joqi10WGkHMk34GodwEziQBmHJ01TI3d5Sz6cFLxm8iV6lJ/H/1AEAAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKDR+jZ/PHz577UNkZSXUbGkfGJ+bCHB9Y9b6NiWOaovLfp8OgAL3bNVjuc3suDjmfL2z5BFOIBzibs3HMoV7UCmmZ1nLmyOJS3coeyzpOTmSK//fDA7943mDTkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBG61v99TC8/PeaXj/hW7TUwQXW/XdRsaRvwZyLCi5Z3qEczyRr9hYJHoEDOZgHMs3lWvQNhdtyNIHbcM14uwS/bi57cyz12SV6AJbq1dfeG3IAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0Gh91wN4fcNy04Zc2oJnGY1b7DzDS3YQgvu/yiH4ZpZ5DjiWbxub4y5ZMgB4de6btzcnww7hANxijt6QAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaLS+zR8PX/5bkiE+oKXN8FsQnuJiVyw4sMXOMS14Qh3MmiXlL2gxyx0Zt7bgfbZUVgx4ayz6u9MczAqOKzmsdOBSl5+3ylK32VKfz24zLm/IAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFrfyacOw5187CsJDm3Bs1wwq3ZrwfPpYFZ/ydegoMOY5ZIt84ZiX/BGSm7cOZiVlD45k/M8mAvHUid6KAdzoWOLD+tQ5rlQs5vAXTqUbfaqvCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQaH0XHzrcxYe+osWObciNbLFzrFrw4MIDW+w8l2yZi7bMUR2Q4LURDt6CnzXmYFbyshEdVzDr2wnk7jiYb5PkdYNv4GCeHZM3O7v22+INOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABotL7rAfBqhrsewNfKjW6x81zswA5I8Bg4nN/AYNXuktV/yyz0fFrmqF5a6tiWOi5guVw33h7zXQ+gTXLXHs6qvQpvyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRa3+qvh+HlvyVZ2nh+32LHFh7XUqeZHNici6pa8NZIrtmhbLNFs2q3ZcX4/zMs96INANyRJT8dRL++RieaDAt/SQ/HvQpvyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRa3+aPhy//LcnSxnOIFnsMggNb7ByraqkTXfaaLVV41RZ6EBY6LL6pYZlHdJmjAgD49h3Cc9C81O9Ot3g29oYcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAo/XdfOxwNx/7SnJjW+wsFzuw5ZrDedlDkBydzXF7wTVb8PIveGjc1pA9msm09LUW4M5Er7WujnfK8sMiLfX7yW3G5Q05AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGi0vosPHYa7+NRXtOSxhSx6igvdHMscFYuw4M2x4KEtWHLV5lzUQq+NaYcxS/gD4ifAMs+ohV5lF26Zx/JgxJf/cHZujCXjLeUNOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEbrW/31MLz8tyTh8Sxsdr8zLG3d/zPLHNsyR/UtCO6Ng1mzhbL+CzDMybBgVs4yRwWNoieBM+oupVd/qXeA5LjSnAHfxDJXLbvPwrt2mUuWteQTnW+NN+QAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAare96AG+34a4H8MY5mBUbcjO1ZpC01H02B5Oyc1zqisEftsxdu8xRHZalHoOljou3S3KfpZ81snLPVFHpJVvoNPnPeUMOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACg0fo2fzx8+Y9XdCiLdQjzPIQ5HhCHkz9onu96BN++IT3H5BmVHJszHQDuwrLvwLnRZZ+ows9nSz0IB/CofRvekAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARuu7HsDrGt6AxOU5hDmmZdfsII7AQUwS3kBzOi4XmBzakJ5o0pC7QA7Ri+2C1yxpDs4zeCzTq+82DPDtWvI3xMXe0aOPLYud5SvzhhwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAECj9Z186jDcyce+kgUPLWaYs3FLXbTgPlvoDJctu80Wfdng7THPuY077XaxrJuby1jW9YvnsayqqotnT2JZ+91NLCt4KGt3c50Lq6rN9iiW9eC7349lHZ/dj2WNm9wcq6pWq4X+hhzcaIMbHQALlLw7hb8ivvEW+nQDAAAAAG8nhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFrfxYcOd/Ghd2C581zuyHiLDPbZ22SOhk2xqKsXz2JZVVVffPxRLus3v4plPf3sk1jW+dPPYllVVdcXL2JZu/0+lnV9k8u6utnFsqqq1uMYy3r06GEu6513Y1mP33s/llVV9Z0/+bNY1tk778WyhlXwt+3ohTZrcE8HeKMs9aqdHNccvzeFbsS3GJY35AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABqt73oAr2+46wH0GHLzPJAV45sI7jPu3lxzLGt3dRXL+ugf/u9Y1i/+w1/Hsqqqvvj0t7Gs68vcmk3TPpa1Sp/nwbhpymXt9rmwm+TAqmra5Y7nk08/jWWdP/0ilvXko1/Fsl7m/SKW9eO//O9iWQ++98NY1vroOJZVVbVa5X53n3O3k/CjhucWADKG0D3lNjnekAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARuu7HsDSDHc9AOBgzeG8q+fPY1l/91f/Syzr5z/7d7Gsi/OLWFZV1TTnjkIwqobgzWkVvtElx5a8CyeHlf71cg5ujv0UzNrvY1kXV1exrKqq+Te/jmXdXPxPsazv/4t/Fcv67p/+eSyrquro7EEsaxiDZ8EcPM89uAMcrLfhFuANOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEbrW/8Xw/AtDAPy7FQ6zMGsy+dPg2lVf/u//c+xrL//2V/Hsi6vb2JZ+2mKZVVV9oAGrYIXtFX4Pj4Gf9obh1zYOObmuQ7/fLmbchttCp4Du33wBJizJ9NlMG9+8iSWtfub/zOWdf38i1hWVdX3/+W/jmWdPH4vlrUab//1o8vgew4AjbwhBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0Gh91wN4bcNdD6DHoqcZHdyiZ7pMC12yhQ4rbn9zHcv6+b//P2JZVVV//7N/F8t6cZmb5zRNsax5mmNZVVXJtFXwJBjH3O9nx+vsb3GbYN46uGgnR5tY1nY9xrKqqi6vb2JZzy9y5+ZN8Hza7XPneVXVPAfPzjk5tty4fv2f/kMsq6rq+vxZLOuHf/HfxrLufe9HsazVuNyvMoPnYwD+CG/IAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFrf9QB4NXMwawhmVVV4cLmwOTjT+JolLXpzLFVuok8//k0s64P/+LexrKqqi6urWNZ+P8Wy5jm3aacpN660cZ37zev+6VEs6/G9k1hWVdV2PcayNsGsB2e5eZ6cnsayqqp2N7tY1qeffRbL+s3nT2NZ51e5OVZV3exzWXPwxjkMyRtn8oZe9emvfxHLWgWn+f6YO8/PvvP9WFZV1WpMfjUKvvcQfD4eDudhD2DxvCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI3Wt/0Phm9jFPA7uR12MHv1YCaas99dx7I++fDnsayLFy9iWVVV85zMyoXtpymWNU3BSYadrW99i/2DHj+8H8t6dO80llVVdRSc59E2l3VyehLLOj7OZVVVrcbcPO89yO2N45PfxLI++PDjWFZV1dPL3HV7t8tdg1a1i2UNlb2eJR8PPv/oV7GscfzfY1nf/bN/E8uqqjr77g9iWevtcSxrSL5DMaTvmx5EAb4pb8gBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0Wt/1AN5qw3DXI+AgLHOfzeG85Cx311exrOvL81jWZruNZVVVDcFr0DznjmgyawpmvZTLOz46imWdnpzEso62uXFVVR1tNrGs7Tb3WLJe58ZVqzGXVVWr4NhO7z+KZb0/5uZ5dX0Ty6qqOv/Vx7Gs6/0Uy9rlomrYpe/nu1zUfBmL+uTDD2JZ0xQ8AFX17vmfxbLOvvfjWNbRvYexrNWY/frn6w7AN+cNOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEbrux7AW22ec1nDkMviLRPcZ5XbZ+kdm5xlDbnfIjab41jW8elpLKuqav30aSzr6vomlpW8NM7ZnRHdt0fbTSxrXI2xrCl5ACp8DFa5I5Cc5X63C6ZVzcFjsN7k9tn26CSW9d533o1lVVX99tMnsayr55exrN0+dyxXwz6WVVVVu9zYoo+0FxexrM8++mUsq6pqmHLHYH2Uez5Yb49iWUPwPK+qquD9afB9B7iF7BNt/vvrq/CGHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQKP1XQ/gtc3hvGGxYfAH5PbZoezYcZ279D1+7/uxrOuL57GsqqovPn8Sy7q4uI5lVU2xpDl8DxhXud+pNsF9NgcnutvvY1lVVZfXubGtN2MsqzabWNS028Wyqqr2u5tY1rTPZW0221jW6dlZLKuq6tGDe7GsL86vYlm7KXc9q132LrwO/uyevNaugtMcx+S9qer82RexrItPP4plHT98J5Y1bo9iWVVVw2Lf7ziUp1o4XG/DWb7UKygAAAAAvJUUcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI3Wdz2A1zbc9QC+zhzMWvREuVP22W2txtyl7/EP/ySWlTySVVUfffDzWNaLi8tY1vV+H8tK79hxzCWu12MsaxPMGo+OYllVVbvr61zWzRTL2tzbxLIudrlxVVVdzrnfQx+scnt2nnJXoXHM7dmqqkcP7seyPvz481jW9X4XzMreBYKHs6Z5mc8a45i7n1RVXV6cx7Kef/pRLOv03e/Hssaj41hWVdVwdJYLC143DuOJFnjTeUMOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACg0fquB8CrGe56ACxYbnfMsaRl79lhyI1uXG9jWacPH8Wyqqq++/33Y1mX17tc1uVVLGu/n2JZVVXjaoxlrcfcb167IZf111cnsayqqn9+nDsHHq/3saztNjeuX97kxlVV9TfPclfb/+F7x7Gs7XQZy9pP2bvA2dlpLOve8VEs6/wqd23cTcm7cNU05a6P0yr4rDHn1ix4O6+qqlVwntsnn8ayzj75MJa1vf84llVVNW5y95QheA9e9IMowJe8IQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBofdv/YA586BDI+J3EgH5fdHDQIXkSLPcESI5sTqYNUyzq+N7DWFZV1U/+y38Ty7q6vollffbZZ7Gs65vcuKqqhiG3N8bVrW+xf9BR8Oez//pklwurqvnmOpa1HrexrOQ14ydnuWNZVfWD01zW0WqfC0v+TrvPXRurqk6Oj2NZf/4nP4plXf7dL2JZv336PJZVVbVa5Y7nvM89ayR3xu4yew+YptzoNmNu/Z9+9EEs6yj8rLE+PollDcE1q2HMRS34+Rh4s3lDDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoNH69v/JHPjYIZCRj1qyxKp/5UCW7IA4orc1JJdszoWN620sq6rq7PHjWNaP/tmfx7J++Y//GMs6P7+IZVVV7efk1TZnCO6zB8MUy6qq+vwydwye3VzGsrar3G+Ox/cfxrKqqtbrb/D49YcE9+xUwb0RPpdWweN5du80lnV8chTLuvn8aSyrqmqbvNkFs3b73D7bpR+BrnL7dnt+Fcs6ff5FLOvkNx/Esqqqtmf3Y1mn3/tpLGvcBN87iT44AvwTb8gBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQKP1rf+LOfCpQyDjK4nx/L7k2KDDHDwJhkM5AdIXjoz06o/bo1jW5uQ4ljWOuZmOq+zvSjfXN7Gsq5tdLOtmP8WyLq9z46qqWq/GWNbxUW7Pro9OYllT8jpbVcMuewxSpmkfy9rPuayXcteNffBwPn1xkQsLG6KPB7n1H6L34Oydcw7mXe1y1+2rq+tY1vXl81hWVdXN86exrOk7uXvwar2NZQ3Jk+llYjgPeFN5Qw4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKDR+q4H8PrmcN4QzlueRa9YcHBzcGCL3hULPQBzeNWWnBaTHlbwJLh48nEsa1zlxrXdbmJZVVXPXpzHsj579jyW9eDsJJa12WU32rTPXTc++eUnsaxhl/vN8cF7j2JZVeH7cPBwzvt9LGuaplhWVdXV5VUs6xe//E0s67NnuWvGOGR/Jx+C19pkVnLTjkP2erYZc8dgvR5jWZuj01jW+vheLKuqahUc2zzlrkE1565B85w7llVV4W0LvMG8IQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBofdcDoN9w1wP4WnMwa9kzjYku2XLXLDnNqOSShSe53+1iWVdXl7Gsx+9+N5b17Pl5LKuqql5cxKKePH0ey7r6zruxrPV1bl9UVW3XYyzr4XuPYlnbs00sa7/Prln2TpdLm6Zk1hTLqqr6+199FMv623/4VSxrSN43w/fgVfAGNUbnmYtKXn+qqk62uevG8dFRLuvkLJZ1dO9xLKuqan2aG9tqzK3/gp8cAX7HG3IAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACN1nc9gKWZg1lDMCs5sDk6sPA8oUXyhApGzckrUNU07WNZj777o1jW9flFLOuXv/jHWFZV1WqVu6K9uMjN87Onz2JZ60f3Y1lVVeOYW7Pje2exrM3xUSwre2ZW7Xc3sax5oU8u1ze5OVZVff7Fi1jW0Sb3+LubcuufvgcMwQe0zWbMZa1z659+Bj05yV03zk5z17Npdx3LmvdXsayqqiF5FJKbdvDeCSxR8rlluT3Eq8/RlQoAAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGq3v4kPnYNYQzDoYyQNQdRAH4WCWbA7OdFjsLBcsu9NWY+4Sf/b4cSxr85ujWFb6ZBoWum9/++lnsayH905iWVVV87TPhU1PYlFnl5exrM1mE8uqqhrH3D4bg+f5asz9Tnt+kVv/qqrrm+tY1nYzxrJqN8Wi9lMuq6pqFbyebYPnwKOHD2NZu91NLKuqah08B05Oj2NZZw9z9+D9PrvP5uA+G4bc+g/JB4RlPhrAGyl5bs7h7065sb16jjfkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGq3v5FPnYNYQzKpa8NiSA0tLH4SQObhmw0LnyDeUPJ6LvWjUerPNhc1TLGq1GmNZmzF7G1sFz/XVkPvN6/rmJpi1i2VVVW2PN7Gs3T63z252uXluNrk9W1W1Xh/nsja59R+C+//5i4tYVlXV8fYolnVd17Gsed7HstJPGqtV7hq0Ca7/vYfvxrKOj3Pjqqra73N7YzPmjujpg8exrLPv/TSWVVW1OXsQyxqS9/TgCeVbAIduyU1E0hya6W1yvCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQaH03HzsHs4ZgVtWyxwZvkuS5FI5b6Kk5pMe1yv3mMoxjLGt7dBzL2hwdxbKqqlbJNZumWFZWdqMdH+eOwenRJpd1vI1lHYf32WaTm+cqeG7u97tY1rMX57GsqqrtOjfP1XgSy9ps97GsZ89fxLKqqsZ17nq2Ct6gxjm3z+6/+8NYVlXV6cN3gmnBB5fdRSzq6P6DWFZV1eb4LJa1GpLviiz0YY8FWOaXivA3p7CFjm6hw7rNuLwhBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0Gh91wN4m81zLmsYcllpwWnWYqeZPJhVNQcP6HLX7K4H8DUWO7b00ZxiSfN+H8s6Pj2JZT1+571YVlXVxx9/Esvar3LHcxW8ZqyC46qqWq9zjxJH220saxPMWm82sayqqjG4ZsMq99vqPnieX9/sYllVVVfXF7Gss3uPYlnjOrfPzs9zc6yqOg6eA0PwfnJ1+SKWtb86j2VVVR3d+2ks6/jhu7Gs5HPLapPbF1VVQ/JLykIfavOPjYt9EOXWDuRYHsg074I35AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACg0fo2fzx/+e91DYGMr8xzYkT/ZBiiowsm5caVnGFa8mgueZ5J1ow/KLg5pv0+ljWsNrGsm91lLKuqoifBKng/WY9jLGtc3+rW/0cl75urVXCewTUbgllVVZUcWyypqla532lP792LZVVVXV5cxLKOj49jWatxG8vabnNZVVXHJ6e5rG3uupE8N6MPQVU17aZY1rhJ7rPgdTv6XScd50mUN0z4GsTh8YYcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAo/Wt/nqeX/57XcPw+hmHJrHuX0mv/5LHtlTRNctFzcGwAzmSyxY8n4ZVLuvyxdNc1hefx7KqqlZzbp6b9e1usV/n6CiXtQoey7Tg8lcNud8ch9UYy6qqGtabXFZwnuM6N88f/fQHsayqqunmMpZ1fHIcy7q8zI3rwYMHsayqqnsPH8WyTk7PYln3gvN858f/LJZVVXXy+HuxrGHMXbeHlXco7lTwsf1gpB81HAPeUq7uAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjdZ38aFzMGsIZlUte2wHYc4dgXnIHYFFH0ublj8keA6sN0exrJMH78Sy3nn/B7GsqqqPnzyNZQ1zbv0fPnwYy9psx1hWVdX25DiWtQ5mraJZ92JZVVWr49zYhvUmlpVLqnrn7EEwrerzjz/LhQWvjdN+H8vabrOP5d//6Z/Gsu6/+71Y1vroJJZ1+s53Y1lVVeNmmwsbvPfAAUt+P4G3mDsFAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAI4UcAAAAADRSyAEAAABAo/WdfOo857KGIZdVteyxhczJOVbVsNB5HsKxjAuu2RxeswM5AlHJNVuNudvFox/8NJb144vnsayqql/+x3/IhZ1sY1H/xT//SSzr5PQkllVVdXp6Fss6Oj6OZW2Oclmrde5YVlXVmPw9NJmVuwdsTnL7oqrqp3/xX8Wynn/xJJZ1EbxmXF+cx7Kqqtbb3L49ffe9WNb6KHcNGsPn5qE87gGwDN6QAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBG67sewNtsnnNZw5DLSgtOs5Y6zeQcq5Y7T/hDhlXu95txu41lvfvTfxHLqqr6l//6v4llXV5+HMtab3K369UYvvUPub0xBy+O+2kKhu1zWZX9NXQ15hZtCB7L9I3u9NHDRWZtj09iWR/83f8Ty6qqmnZXsaxV8B6wGjexLAAO1xz+lj7cwbd0b8gBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0Wt/mj+cv/+d1DTW8dsZX5vn1x/P7hiE3tgqs1T8l5caVnGFVVSWPQXT9g8L7bLHzTAov2RxcsgNY/UVLrv/R6f1gWtVP/vJfxbI++cXfxrLG9RjL2gSzqqqGMZc3TbGoWk3Be/AYvqAt9Sp0CPemqkqu/+PvfS+WdfrgLJZVVTXPud/d9+efxLKG2sey1scPYllVVfOQu54dytkEvP3ST0FLlei6bpvjDTkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBGCjkAAAAAaKSQAwAAAIBG61v99fzlv9c1BDJ4K81zYoO9NAzL3Wi5WWZlVyw8y2DcHNwby91lCxZc//MvPollVVV9/tHPY1nrzSaXtR5jWeOY/S1uNebGNqyCYwuenMFb08u84AUtObYhGpb+zXeZd8797iqWtbu+jmVVVR3fexDLWg1TLGu6+DSWtZtuYllVVevT78Sy5uT1LMhzC+Rk70zp+1zybE9+EctFLdYt5rjMOwUAAAAAvKUUcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQaH0XHzoHs4ZgVlXVPOdGNwzB0QXHNYdXLTnNpCXvs+TxXOwBWLLk+RRd/vgVLZa0GsZY1vnTT2NZH/3Dz2JZVVU17WJRm01uzYbgsTycK0Zypsk7StU8T8Gs3DyTWUPl5li13Hv6zdVlLGu/u45lpQ1D8Df85OPx9fNcWFXtVrmvRuvTx7Gs5KLN4esZHLSl3pyqst83+dZ4Qw4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGq1v88fzl/9e1zAnUr4KG3JZYcudZnBgVVW10GOw3AOQdSjzXKro6ZQ9N4ch95vL5cWzWNav/+Fnsaybq4tYVlXVZnOr2+LXmucpljUFt8Zqzv4Wl5znPOeuQXPw2jgnD0BVzUNwzWJJVVNwzYZVdp8l8+Z5F8u6ubqMZa0221hWVYUfz5I7LTiw8GPLfPU0ljWtc8dztb0Xy4p/DUha6mPokteMt4d9dpC8IQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBofau/nueX/17XMLx+xpfmxHh+zxAcW1VybMlxZSWPQXb9c5a9z3LS80xa6polpee4213Hsn79n/59LOv82ZNY1jiOsayqqv20j2WtpuC1MXg/2afvJ8G46B04GJa+Mibzpuh1O7j/w+fmas7l7XdXsazdTS5ruzmKZb20zOft6BUo/mwwxZL2l09jWcP6OJc1ZM/NqOU+hgJ8K7whBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0Gh9Fx86z3MsaxiGWFbVcse21HHxzQQPZx3K4QwuWS11yZJzrKr67MO/j2U9//y3saxpXua1sapqGHJ5qyF4i03eA2JJX+YFA5NjW/a9Lng8g+dTcp/N8z6WVVU1r3Ln0/XleSzrZreLZW3DZ+c8TbmsYZm/4cfP8uSz+/4qljVdX8SyxqP7sayX0k8vAK8m/T0gdQ+4zaiWeXcFAAAAgLeUQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGinkAAAAAKCRQg4AAAAAGq1v88fzPNc8z6/9ocMwvHbGm+D1V+qfJFdsjo6sagiOLrG/vrLsfZab5zzn5rnsJQuuWSypaljlftd49vnHsayqqk8//Hksa56mWNZ+n8tarcZYVlXVrnJjG1fBEyp5nseSvsyLXjhy6z9Ez/Tw75dzMC+6/rk1Ww23esT8o+b9VSzr8vx5LGt3cxPLmqZdLKuqatrvY1nR8zx430yfm8ln2uT5NF0/i2WttqexrKqqYfB+B2+W7Ddh3i6p3fHqOa6gAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBofdcDeF3zPEfzhmHIhSXHFh1XLqqqah5ygUPl5pncG9F9EZc8oEue5zLN0xTL+vw3/xjLqqra3VzFsqbgPPc317Gseb2JZVVVzXPud6pxdRPLWq/HWNYUP82T96fcPOdpl8saso9L8yp4f5qD65/cG3PumlFVdXN9Gcu6PD+PZdWQ27M3V7lrdlXVGLw+rlZLfT7I7rMpmTcFn892ufvm6vhRLKuqatycxLIO5Yl2Tn8Z45YWujvCvQbfQOoQ3CLHG3IAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACNFHIAAAAA0EghBwAAAACN1nfxofM8x7KGYYhlVS13bMFhVXjJqoJjq/TYQpL7oqqi8xyCYdF5hjfaQrdGJUc27adYVlXVfncTy5rm3Nim/S6XFT4315ttLOvmJrf+qyF4bwrf+Yfgb3vjasxljblzc1znxlVVVcHzqSp73YiZcud5VdXu+iqWdX11Gctab49iWTdXF7GsqqrVKndurlbB82kMXoSi51JW9Pa0u45FjTe5c6mqatycBNNyi5Z+dF+s5APyoazZ4UyUN4A35AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABqtb/PH8zzXPM+v/aHDMLx2xlcS4/l9Sx1bcFiVXbGqoZa6ZsFFS0sehKVOM3xuRpdsyP0WcfHii1jW+dNPY1lVVdN+H8va73exrGnKjWva5bKqqlbjGMsa1rmszfZWt+uvtQ1mVVWtx9xFaAz+TLgOhg3DFMuqqho3m1jWULmxzXMuaxhy+7+q6jp4DG6uLmNZq+Czxs0q+zt58jkoeQ5sj45jWevtSSyrqmpcb2NZQ/B47oP38/Q3gWha+kvKIbBm8EbzhhwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAECj9V186DzPsaxhGGJZVcsd21zBcc3ZNatwXMpSj2Vacp614HkudWRffPLrWNbN1UUsq6qCV42qab+LZd3c3MSyVqsxllVVtd3kbotH21zW/Qf3Y1nbbXbNKrg3kuf5MAZ/cxyyv1+uVrm8IXoO5I7AMGT32b1H34llXV2cx7I+/+zzWNY872NZVVXjmDsG+3XuejZvplhWXvLOmTOOm1jWsMplVVVV8jkUeOsdwhXjNnP0hhwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFrf5o/nea55nl/7Q4dheO2MryTG8/uSY4tKTjM8xegxCK5/cpqHs8+y84yKrllunif334llDeOtLsl/PG+/S6YFo3JZ9x89jGVVVR1txlzYvI9FrYbcnh2H7G9x87iNZa3G3PrP0xTLGlbZc3O1Pg6GJfdsbp/NU/L6U7U+Ootlvfv+n8Synj+/iGU9+exJLKuq6uj4NJY1z7nzKZlVyayq7MNj8rkl+Xw23eSyKvsVZanST+2HsGZ8E+GdMS/zu9NBuMU12xtyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjdZ38aHzPMeyhmGIZaUtdZ7JcVWFj0FwbHNwWENl91n6GKQcyvk0T1Ms6/nnv45lVXBcadO0j2Wd3bsXyzo5PYllVVXtdxexrN0ut2f3N7tY1rzdxrKqqoYx+CgxBH8nXOWyVutNLKuqag7Oc5V8PoglVe1uroNpVePmOJa1PjqNZb33wx/Hsl48exbLqqq6urqMZW1PzmJZ0WeN5DWjss97ySeq5Lk57bPn5mqhz7RJb/8MeTvZuW8Cb8gBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0Wt/mj+d5rnmeX/tDh2F47YyvJMZzaILLX1VVyUOQ3BsVHNecDKuKHoTk4Vzy+ZTcGze761jW8yefxLKim7aqpmmKZa3GW90uvtbZvfuxrGfPX8Syqqrm610sa328iWX9/INfxbJ+8qMfxbKqqu49eBTLip4BQ/A3x1Vu/78UfA4KZiWvs/t97lyqSl/Pcnvj7OHjWNb9Rw9iWVVVT794Gsu6HzzPp2kfy5qDWVXZsQ3R5+Pg9WzKnpvJZ8fo9wB442S/BySfD6IW/H0z5TbXRW/IAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFLIAQAAAEAjhRwAAAAANFrf5o/nea55nr+tsXwjwzBE85LzS45truC6z9k1G4bc2Ba2vX4nvc+SE00uWXyeQclzcxw3sazN9jiWdfX8SSyrqmre72JZxyensaxa5X4Levb8IpZVVTVPuX32w3cexLK2p7n1Xx8Fj2VVDasxljVPUyyropez5V4bszeBYFbYFLyercbtIrMePH43llVV9dknn8eyri5z19ppv49l3WzPY1lVVcen92NZq/FWX7O+1u7mOpa1On4Uy6qqOrv3/VhW9vtOLqoW/HwcnWfUYgd2QByDN4E35AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACgkUIOAAAAABop5AAAAACg0fpuPnbOJeWiqqpqGIZY1hwc3FDBcQXX/6Xc2JJ7Y6nHMu1Q5pm0WuUufccnD2JZnzz7u1hWVdV+v4tlnT54FMvabrexrPe//14sq6rq/PoqlnV2dj+WdXxyEstar7O3/jl6f0pa5r3ppYXe04NRq9WYC6uq/X4fyxoXeqs7u/8omrda5fbZs8+fxLLOjo9jWesHD2NZVVXT+jKWNQy5c2C6zt3Px9OjWNZLyWtQ8roddCDPx/CmWep319uMyxtyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjRRyAAAAANBIIQcAAAAAjda3+eN5nmue58DHDoGMryTG8+0Yhtw8M+v+UnJcVcsdW3Jc0S1bVUMwcKnzTM4xbZp2sazzJ5/Esq6fv4hlVVWtj7a5rPWtbhdfa7PexLLGVXafJS+P601u/cdxjGVFJ1nLvQYlRef4MjGWFH2iSt4DhuxvvvM05bKSzy2xpKrN0Ukwrer07CyWdf75k1jWve1RLGvY7WNZL/OCe2PM7Y7VUe4enBxXVfp7QCwq+w0xfQuI3oeXeT1b7jf0WvjgODTekAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGikkAMAAACARgo5AAAAAGi0vs0fz/Nc8zx/W2P5RoZhiOYtbX5fSU5zoVNctKHC+6xyByF6DgT3RnKOVdl57q6vYlnPP/sklhU9AFW1ObsXy1qNYyxrWOWO5bxf7j5LXjeS1+0hfQ+I3p+y19qU9H1zCB6Exe6NIfubb/L5bJ6mWFbyAW1Y5a6zVVUPHjyOZT379LNYVtI43uqrzB+1WuX2bfRZb3UUyxpP7seyqsJPLofyHWWhX8aWOSqWIbc7zj/exrJefLKPZVVVDZtM3vPnr/633pADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABopJADAAAAgEYKOQAAAABotL7dn89f/ns98+tHsCBDMMvW+CaSq5Y8mlnDkBvb5Ytnsayr8+exrNV6E8uqqtqenMWykus/TVMua5/Leik4zzk3tjl444zfg4dk4DLnmVz/qqrg1ghftpNh4fvJQs+npCG8Zqf378eyjo6OY1lZ2TWLPlEF9+ywPopljUe5Z4Oqil5s5wN5poVDdvM3uXPzt//rVSyrquq9/zFzDZpf3Lzy33pDDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAaKeQAAAAAoJFCDgAAAAAarW/zx/M01zzNr/+pw/D6Gb8TGM/vGYJjm+fk2Ja7ZtHjGVyzIbhm86L3WSyq4nsjKDmy86efxbJ219exrPXxcSyrqmq9GXNhwY223+1iWdM0xbKqqubkuRkcW3Ke0VtwVdUU/G0ve0GLSR7Lqqp5tdTfQ3Prn75vJuOSx3MIHsv07t+enMayzu7dj2Ut+rklOLgp+By6WiefD4LPBlU1Tze5sOFWX02pBX+tTj9rJC3zUWOpw4p79Kf7WNbJo+zz1OlfbiM5T5+9+nVxqU+EAAAAAPBWUsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0UsgBAAAAQCOFHAAAAAA0Wr/KH83zXFVVz58/z3zqkOsBhyEW9WVeODBkqeOqWu7YhgqO60D22ZKtxjGW9fz5i1jW+cVlLGucY1Ev887PY1k3u30sa73OHcv9bhfLqqqak+fmnMtab29iWeOY/S1uCN7Taw6fBCHJ609V1WoVXLPgnk3emfb73J6tqpr3Uyxrvc1dN6LHMuz6Ineve35+EcvaBPfsanMUy6qq2u5z16A5eEatxtB3sKq6Pn4Wy3opeB8eXumr6auGBbOWK/qVInkLXvLyL/NRY6nDils9z53n1y+yzxq7Z5tIzrNnL6+z8ys8177SanwV+N//23/7GsMCAAAAgLfbs2fP6uHDh1/7N8P8CrXdNE314Ycf1v37973ZAwAAAAD/H/M817Nnz+r999//o2/Sv1IhBwAAAABkLPf/8AUAAAAAvIUUcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI0UcgAAAADQSCEHAAAAAI3+X5DhV+MPHdIZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_test(t5, if_I, None, \"a photo of a doll at the beach\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
